{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import bcolz\n",
    "import keras\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "import codecs\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from gensim.models import Word2Vec, KeyedVectors, word2vec\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from bcolz_array_iterator import BcolzArrayIterator\n",
    "from string import punctuation\n",
    "from keras.layers import InputSpec, Layer, Input, Dense, merge\n",
    "from keras.layers import Lambda, Activation, Dropout, Embedding, TimeDistributed\n",
    "from keras.layers import Bidirectional, GRU, LSTM\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from keras.layers import Merge\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, Reshape, Lambda, Conv2D, Conv1D\n",
    "from keras.layers import merge\n",
    "from keras.layers.merge import concatenate, dot\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, BaseLogger, ProgbarLogger\n",
    "\n",
    "import sys\n",
    "np.random.seed(7)\n",
    "np.set_printoptions(precision=3)\n",
    "# !pip install gensim nltk keras pandas bcolz h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'30_64_0_1_0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SEQUENCE_LENGTH = 30\n",
    "MAX_NB_WORDS = 200000\n",
    "EMBEDDING_DIM = 300\n",
    "VALIDATION_SPLIT = 0.1\n",
    "bcolz_chunklen = 64\n",
    "stem = 0\n",
    "init_random = 1\n",
    "stop_words = 0\n",
    "bcolz_prefix = '%s_%s_%s_%s_%s' % (MAX_SEQUENCE_LENGTH,\n",
    "                                   bcolz_chunklen,\n",
    "                                   stem,\n",
    "                                   init_random,\n",
    "                                   stop_words)\n",
    "bcolz_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv.zip')\n",
    "df = df[(df.question1.isnull()  == False) & (df.question2.isnull() == False)]\n",
    "print(df.shape)\n",
    "train_df = df.iloc[:380000]\n",
    "val_df = df.iloc[380000:]\n",
    "test_df = pd.read_csv('test.csv.zip')\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X1 = bcolz.open('bclz/all/q1_%s' % bcolz_prefix)\n",
    "# X2 = bcolz.open('bclz/all/q2_%s' % bcolz_prefix)\n",
    "# y = bcolz.open('bclz/all/y_%s' % bcolz_chunklen)\n",
    "\n",
    "X1_train = bcolz.open('bclz/train/q1_%s' % bcolz_prefix)\n",
    "X2_train = bcolz.open('bclz/train/q2_%s' % bcolz_prefix)\n",
    "X1_pos_train = bcolz.open('bclz/train/pos1_%s' % bcolz_prefix)\n",
    "X2_pos_train = bcolz.open('bclz/train/pos2_%s' % bcolz_prefix)\n",
    "y_train = bcolz.open('bclz/train/y_%s' % bcolz_chunklen)\n",
    "\n",
    "X1_val = bcolz.open('bclz/val/q1_%s' % bcolz_prefix)\n",
    "X2_val = bcolz.open('bclz/val/q2_%s' % bcolz_prefix)\n",
    "X1_pos_val = bcolz.open('bclz/val/pos1_%s' % bcolz_prefix)\n",
    "X2_pos_val = bcolz.open('bclz/val/pos2_%s' % bcolz_prefix)\n",
    "y_val = bcolz.open('bclz/val/y_%s' % bcolz_chunklen)\n",
    "\n",
    "X1_test = bcolz.open('bclz/test/q1_%s' % bcolz_prefix)\n",
    "X2_test = bcolz.open('bclz/test/q2_%s' % bcolz_prefix)\n",
    "X1_pos_test = bcolz.open('bclz/test/pos1_%s' % bcolz_prefix)\n",
    "X2_pos_test = bcolz.open('bclz/test/pos2_%s' % bcolz_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'att_06_04_30_64_0_1_0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.set_epsilon(1e-07)\n",
    "np.random.seed(1)\n",
    "STAMP = datetime.now().strftime('att_%m_%d_') + bcolz_prefix\n",
    "STAMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _Attention(object):\n",
    "    def __init__(self, max_length, nr_hidden, dropout=0.0, L2=0.0, activation='relu'):\n",
    "        self.max_length = max_length\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dropout(dropout, input_shape=(nr_hidden,)))\n",
    "        self.model.add(\n",
    "            Dense(nr_hidden, name='attend1',\n",
    "                kernel_initializer='he_normal', kernel_regularizer=l2(L2),\n",
    "                input_shape=(nr_hidden,), activation='relu'))\n",
    "        self.model.add(Dropout(dropout))\n",
    "        self.model.add(Dense(nr_hidden, name='attend2',\n",
    "            kernel_initializer='he_normal', kernel_regularizer=l2(L2), activation='relu'))\n",
    "        self.model = TimeDistributed(self.model)\n",
    "\n",
    "    def __call__(self, sent1, sent2):\n",
    "        def _outer(AB):\n",
    "            att_ji = K.batch_dot(AB[1], K.permute_dimensions(AB[0], (0, 2, 1)))\n",
    "            return K.permute_dimensions(att_ji,(0, 2, 1))\n",
    "        return merge(\n",
    "                [self.model(sent1), self.model(sent2)],\n",
    "                mode=_outer,\n",
    "                output_shape=(self.max_length, self.max_length))\n",
    "\n",
    "\n",
    "class _SoftAlignment(object):\n",
    "    def __init__(self, max_length, nr_hidden):\n",
    "        self.max_length = max_length\n",
    "        self.nr_hidden = nr_hidden\n",
    "\n",
    "    def __call__(self, sentence, attention, transpose=False):\n",
    "        def _normalize_attention(attmat):\n",
    "            att = attmat[0]\n",
    "            mat = attmat[1]\n",
    "            if transpose:\n",
    "                att = K.permute_dimensions(att,(0, 2, 1))\n",
    "            # 3d softmax\n",
    "            e = K.exp(att - K.max(att, axis=-1, keepdims=True))\n",
    "            s = K.sum(e, axis=-1, keepdims=True)\n",
    "            sm_att = e / s\n",
    "            return K.batch_dot(sm_att, mat)\n",
    "        return merge([attention, sentence], mode=_normalize_attention,\n",
    "                      output_shape=(self.max_length, self.nr_hidden)) # Shape: (i, n)\n",
    "\n",
    "\n",
    "class _Comparison(object):\n",
    "    def __init__(self, words, nr_hidden, L2=0.0, dropout=0.0):\n",
    "        self.words = words\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dropout(dropout, input_shape=(nr_hidden*2,)))\n",
    "        self.model.add(Dense(nr_hidden, name='compare1',\n",
    "            kernel_initializer='he_normal', kernel_regularizer=l2(L2)))\n",
    "        self.model.add(Activation('relu'))\n",
    "        self.model.add(Dropout(dropout))\n",
    "        self.model.add(Dense(nr_hidden, name='compare2',\n",
    "                        kernel_regularizer=l2(L2), kernel_initializer='he_normal'))\n",
    "        self.model.add(Activation('relu'))\n",
    "        self.model = TimeDistributed(self.model)\n",
    "\n",
    "    def __call__(self, sent, align, **kwargs):\n",
    "        result = self.model(merge([sent, align], mode='concat')) # Shape: (i, n)\n",
    "        avged = GlobalAveragePooling1D()(result)\n",
    "        maxed = GlobalMaxPooling1D()(result)\n",
    "        merged = merge([avged, maxed])\n",
    "        result = BatchNormalization()(merged)\n",
    "        return result\n",
    "\n",
    "\n",
    "Dense\n",
    "class _Entailment(object):\n",
    "    def __init__(self, nr_hidden, dropout=0.0, L2=0.0):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dropout(dropout, input_shape=(nr_hidden*2,)))\n",
    "        self.model.add(Dense(nr_hidden, name='entail1',\n",
    "            kernel_initializer='he_normal', kernel_regularizer=l2(L2)))\n",
    "        self.model.add(Activation('relu'))\n",
    "        self.model.add(Dropout(dropout))\n",
    "        self.model.add(Dense(nr_hidden, name='entail2',\n",
    "            kernel_initializer='he_normal', kernel_regularizer=l2(L2)))\n",
    "        self.model.add(Activation('relu'))\n",
    "        self.model.add(Dense(1, name='entail_out', activation='sigmoid',\n",
    "                        kernel_regularizer=l2(L2), kernel_initializer='zero'))\n",
    "\n",
    "    def __call__(self, feats1, feats2):\n",
    "        features = merge([feats1, feats2], mode='concat')\n",
    "        return self.model(features)\n",
    "    \n",
    "    \n",
    "class _BiRNNEncoding(object):\n",
    "    def __init__(self, max_length, nr_out, dropout=0.0):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Bidirectional(GRU(nr_out, return_sequences=True,\n",
    "                                         dropout_W=dropout, dropout_U=dropout),\n",
    "                                         input_shape=(max_length, 300)))\n",
    "        self.model.add(TimeDistributed(Dense(nr_out, activation='relu', init='he_normal')))\n",
    "        self.model.add(TimeDistributed(Dropout(0.2)))\n",
    "\n",
    "    def __call__(self, sentence):\n",
    "        return self.model(sentence)\n",
    "\n",
    "\n",
    "class _GlobalSumPooling1D(Layer):\n",
    "    '''Global sum pooling operation for temporal data.\n",
    "    # Input shape\n",
    "        3D tensor with shape: `(samples, steps, features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(samples, features)`.\n",
    "    '''\n",
    "    def __init__(self, **kwargs):\n",
    "        super(_GlobalSumPooling1D, self).__init__(**kwargs)\n",
    "        self.input_spec = [InputSpec(ndim=3)]\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0], input_shape[2])\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        if mask is not None:\n",
    "            return K.sum(x * K.clip(mask, 0, 1), axis=1)\n",
    "        else:\n",
    "            return K.sum(x, axis=1)\n",
    "        \n",
    "        \n",
    "def build_att_model(shape, settings=None):\n",
    "    '''Compile the model.'''\n",
    "    if settings is None:\n",
    "        settings = {'dropout': 0.2, 'rnn_encode': True}\n",
    "    max_length, nr_hidden = shape\n",
    "    # Declare inputs.\n",
    "    x1 = Input(shape=(MAX_SEQUENCE_LENGTH, 300), dtype='float32')\n",
    "    x2 = Input(shape=(MAX_SEQUENCE_LENGTH, 300), dtype='float32')\n",
    "\n",
    "    attend = _Attention(max_length, nr_hidden, dropout=settings['dropout'])\n",
    "#     embed_dense = TimeDistributed(Dense(nr_hidden, activation=None, bias=False))\n",
    "    align = _SoftAlignment(max_length, nr_hidden)\n",
    "    compare = _Comparison(max_length, nr_hidden, dropout=settings['dropout'])\n",
    "    entail = _Entailment(nr_hidden, dropout=settings['dropout'])\n",
    "    \n",
    "#     sent1 = embed_dense(x1)\n",
    "#     sent2 = embed_dense(x2)\n",
    "    \n",
    "    if settings['rnn_encode']:\n",
    "        encode = _BiRNNEncoding(max_length, nr_hidden, dropout=settings['dropout'])\n",
    "        sent1 = encode(x1)\n",
    "        sent2 = encode(x2)\n",
    "    else:\n",
    "        sent1 = x1\n",
    "        sent2 = x2\n",
    "\n",
    "    attention = attend(sent1, sent2)\n",
    "\n",
    "    align1 = align(sent2, attention)\n",
    "    align2 = align(sent1, attention, transpose=True)\n",
    "\n",
    "    feats1 = compare(sent1, align1)\n",
    "    feats2 = compare(sent2, align2)\n",
    "\n",
    "    scores = entail(feats1, feats2)\n",
    "    \n",
    "    # Now that we have the input/output, we can construct the Model object...\n",
    "    model = Model(input=[x1, x2], output=scores)\n",
    "\n",
    "    # ...Compile it...\n",
    "    model.compile(\n",
    "        optimizer=Adam(),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['acc'])\n",
    "    # ...And return it for training.\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = build_att_model((30, 300),\n",
    "                        {'dropout': 0.2,\n",
    "                         'rnn_encode': False}\n",
    "                       )\n",
    "model.summary()\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "bst_model_path = 'models/' + STAMP + '{epoch:02d}-{val_loss:.2f}'  + '.h5'\n",
    "model_checkpoint = ModelCheckpoint(bst_model_path,\n",
    "                                   save_best_only=True,\n",
    "                                   save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "bclz_iter_train = BcolzArrayIterator([X1_train, X2_train], y_train, batch_size=batch_size, shuffle=True)\n",
    "bclz_iter_val = BcolzArrayIterator([X1_val, X2_val], y_val, batch_size=batch_size, shuffle=True)\n",
    "bclz_iter_test = BcolzArrayIterator([X1_test, X2_test], batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "    \n",
    "class_weight = {0: 1.309028344, 1: 0.472001959}\n",
    "hist = model.fit_generator(bclz_iter_train, 1000, 10,\n",
    "                           validation_data=bclz_iter_val, validation_steps=100,\n",
    "                           callbacks=[model_checkpoint,\n",
    "                                      early_stopping\n",
    "                                     ],\n",
    "                           class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls -w1 -t models | head -n5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STAMP = 'att_05_24_30_64_0_0_003-0.31'\n",
    "model.load_weights('models/' + STAMP + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 24s, sys: 35.6 s, total: 3min\n",
      "Wall time: 5min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!date\n",
    "bclz_iter_eval = BcolzArrayIterator(X1, X2, y, batch_size=64, shuffle=False)\n",
    "pred_iters_eval = int((df.shape[0] / bcolz_chunklen) + 1)\n",
    "preds_eval = model.predict_generator(bclz_iter_eval, pred_iters_eval)\n",
    "df['pred'] = preds_eval[:df.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 10s, sys: 27.7 s, total: 2min 38s\n",
      "Wall time: 5min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bclz_iter_cos = BcolzArrayIterator(X1, X2, y, batch_size=64, shuffle=False)\n",
    "pred_iters_cos = int((df.shape[0] / bcolz_chunklen) + 1)\n",
    "preds_cos = cos_model.predict_generator(bclz_iter_cos, pred_iters_cos)[:df.shape[0]]\n",
    "# df['cos_distance'] = preds_cos[:df.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 24 12:42:45 UTC 2017\n",
      "CPU times: user 9min 22s, sys: 4min 24s, total: 13min 47s\n",
      "Wall time: 18min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!date\n",
    "bclz_iter_test = BcolzArrayIterator(X1_test, X2_test, batch_size=64, shuffle=False)\n",
    "pred_iters = int((test_df.shape[0] / bcolz_chunklen) + 1)\n",
    "preds = model.predict_generator(bclz_iter_test, pred_iters)\n",
    "test_df['is_duplicate'] = preds[:test_df.shape[0]]\n",
    "test_df.index.name = 'test_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_submission(data, prefix=STAMP):\n",
    "    now = !date\n",
    "    now = now[0]\n",
    "    fname = 'submissions/' + prefix + '.csv'\n",
    "    data.to_csv(fname,\n",
    "                header=True,\n",
    "                float_format='%.7f')\n",
    "    with open(\"submissions/log.txt\", \"a\") as log_:\n",
    "        log_.write('%s - %s %s\\n' % (now, prefix, STAMP))\n",
    "    print(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_submission(test_df.is_duplicate)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
